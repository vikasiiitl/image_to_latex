{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to Latex using transformer architecture!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Image to Markup\n",
    "\n",
    "This is a project to convert images of mathematical equations to latex markup. The project is based on the paper [Image to Latex](https://arxiv.org/abs/1609.04938) by the team at Stanford. The paper uses a CNN encoder and an LSTM decoder to convert images to latex markup. The paper uses a custom dataset of 400k images of mathematical equations. I'm using dataset from [latex.codecogs](https://latex.codecogs.com/) with 100k annotated images similar to the 100k dataset used in the paper.\n",
    "\n",
    "[More](https://im2markup.yuntiandeng.com/) about the paper can be found here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "\n",
    "If you just want to experiment with the trained model, you can skip this section and go to the next section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used is from [latex.codecogs](https://latex.codecogs.com/) with 100k annotated images. I used a [script](utils\\download_dataset.py) to fetch and download the dataset images from links in the [dataset.json](dataset\\dataset.json) file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Since the images we'll be dealing with have a lot of white space (since we pass in math formulae images), we'll crop the images to include only the required part (the formula with black text on white background). We'll also resize the images to 256x256. The preprocessing script can be found [here](utils\\images_preprocessing.py). We'll also resize it to ensure that the images dont exceed the max size limits (`RESIZE_W = 1500, RESIZE_H = 175`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The training script can be found [here](train_model.py). The script uses the [dataset](dataset\\dataset.json) to load the images and the corresponding latex markup. The model is a [CNN encoder](encoder.py) and an [LSTM decoder](decoder.py).\n",
    "\n",
    "The model can be trained by running `python train_model.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Since the preprocessing and training take too long, we made the training script save the model after every epoch. The saved models can be found [here](model_in_usage\\checkpoints). We can use the call_model.py script to load the model and run it on images. The script can be found [here](call_model.py). The script takes in the path to the image and the path to the saved model and outputs the predicted latex markup.\n",
    "\n",
    "Let's run this model on some images and see how it performs. The script to run the model on images can be found [here](Image2Latex.py). The script (mostly a CLI :)) takes in the path to the image and the path to the saved model and outputs the predicted latex markup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to catch model in d:\\school stuff\\sem5\\ArtificialIntelligence\\latex-gen\\model_in_usage\\...\n",
      "--Model checkpoints have been detected\n",
      "--Meta and Tokenizer files have been detected\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x _ { m l n } ^ { r } = x _ { m _ { l } } + A _ { m u } . \n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x _ { m l n } ^ { r } = x _ { m _ { l } } + A _ { m u } . $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the model\n",
    "import os\n",
    "from Image2Latex import check_path, CHECKPOINTS_PATH, MODEL_PATH, META_PATH, TOKENIZER_PATH\n",
    "from call_model import predict\n",
    "from IPython.display import display, Math, Image\n",
    "\n",
    "\n",
    "path = check_path(os.path.abspath('.')) + MODEL_PATH\n",
    "print(f\"Trying to catch model in {path}...\")\n",
    "try:\n",
    "    if len(os.listdir(path + CHECKPOINTS_PATH)) > 1:\n",
    "        print(f\"--Model checkpoints have been detected\")\n",
    "    if all(os.path.exists(path + p) for p in [META_PATH, TOKENIZER_PATH]):\n",
    "        print(f\"--Meta and Tokenizer files have been detected\")\n",
    "except:\n",
    "        raise IOError(\"Model files are missing!\\nExpected in '{MODEL_PATH}' folder\")\n",
    "\n",
    "# The image\n",
    "img_path = input(\"Enter the path to the image: \")\n",
    "\n",
    "display(Image(filename=img_path))\n",
    "\n",
    "if not os.path.exists(img_path):\n",
    "    raise IOError(\"Image not found!\")\n",
    "\n",
    "result = predict(img_path, path + TOKENIZER_PATH, path + META_PATH, path + CHECKPOINTS_PATH)\n",
    "\n",
    "\n",
    "# Render the result\n",
    "display(Math(result))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
